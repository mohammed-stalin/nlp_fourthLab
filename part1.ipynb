{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./data/hess_article_content.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~"
     ]
    }
   ],
   "source": [
    "import string\n",
    "for c in string.punctuation:\n",
    "    print(c, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words:  {'أنتن', 'بعد', 'كأين', 'هَذَيْنِ', 'ذوا', 'تشرين', 'إلا', 'ف', 'شتان', 'ثلاث', 'ما أفعله', 'غير', 'هن', 'عشرين', 'حتى', 'تسعمائة', 'بطآن', 'سمعا', 'حرى', 'عين', 'كأنما', 'أخٌ', 'لهن', 'كأيّن', 'لسن', 'هم', 'كليكما', 'مليم', 'فضلا', 'مكانكنّ', 'كلَّا', 'عيانا', 'مئتان', 'ليرة', 'فيها', 'ذواتا', 'حادي', 'لكي', 'أو', 'خميس', 'تِي', 'أفعل به', 'باء', 'سوى', 'صبرا', 'قاطبة', 'تينك', 'عليه', 'أحد', 'هلا', 'سبعمائة', 'يمين', 'بات', 'ثمانين', 'ليسا', 'ميم', 'سبعين', 'منها', 'لاسيما', 'تعلَّم', 'نيف', 'حجا', 'درهم', 'أف', 'ذهب', 'أخو', 'أفٍّ', 'هاتان', 'لست', 'وإذ', 'إذا', 'صهْ', 'أمسى', 'أما', 'سبعة', 'إنما', 'سادس', 'رابع', 'تلكم', 'ي', 'أنّى', 'ليست', 'أيضا', 'تِه', 'إن', 'ت', 'فلا', 'أيلول', 'ألف', 'دال', 'ثمانية', 'عدا', 'أي', 'لستم', 'ستة', 'تسعون', 'لكنما', 'أربعاء', 'أينما', 'م', 'رأى', 'سبعمئة', 'ب', 'تي', 'اللذان', 'لعلَّ', 'إياكم', 'لمّا', 'بكم', 'حدَث', 'زعم', 'أنتما', 'إلّا', 'هكذا', 'ذِه', 'بما', 'سين', 'تين', 'إذ', 'آمينَ', 'الذين', 'وُشْكَانَ', 'تارة', 'اللائي', 'أجل', 'لبيك', 'حبيب', 'ض', 'ما انفك', 'جميع', 'بك', 'أنى', 'أغسطس', 'كيت', 'فو', 'حَذارِ', 'كان', 'ؤ', 'مما', 'إيانا', 'هَاتانِ', 'خال', 'خمسمئة', 'حسب', 'سبعون', 'قبل', 'ذِي', 'بهن', 'إياهم', 'ومن', 'مرّة', 'تحوّل', 'آذار', 'به', 'أنشأ', 'ح', 'لعمر', 'علق', 'حيثما', 'لئن', 'إياها', 'بخ', 'أوّهْ', 'أبريل', 'ين', 'اثنا', 'أنتِ', 'كم', 'بي', 'لكنَّ', 'أُفٍّ', 'أمامك', 'لا سيما', 'ثلاثمئة', 'لدن', 'أكتوبر', 'ضحوة', 'أعلم', 'ة', 'يوليو', 'أخبر', 'مثل', 'إياك', 'مارس', 'بئس', 'لكم', 'شين', 'مئة', 'تموز', 'مه', 'ذات', 'واحد', 'تخذ', 'غدا', 'شيكل', 'أبٌ', 'لما', 'ذا', 'بهما', 'ظاء', 'اتخذ', 'عشرون', 'قاف', 'هلم', 'سقى', 'إيهٍ', 'أرى', 'أكثر', 'ما', 'عل', 'خمس', 'ريث', 'ليستا', 'هللة', 'أضحى', 'أى', 'تجاه', 'آنفا', 'إنا', 'هَاتِه', 'ءَ', 'حزيران', 'بؤسا', 'ق', 'ك', 'ثمّ', 'كثيرا', 'تفعلون', 'أين', 'ستمائة', 'في', 'وإذا', 'هذي', 'ستون', 'لستما', 'كِخ', 'أبو', 'سنتيم', 'هَجْ', 'ثمانون', 'بسّ', 'كأي', 'بعدا', 'ولو', 'تسعمئة', 'أل', 'ذواتي', 'ذين', 'والذي', 'فلس', 'بعض', 'بيد', 'ذلكم', 'أول', 'إياهن', 'مافتئ', 'أمد', 'فيم', 'صاد', 'كذلك', 'كاد', 'رجع', 'عما', 'خلف', 'نيسان', 'طاق', 'لك', 'هذا', 'عاشر', 'ل', 'لستن', 'بَسْ', 'رويدك', 'كليهما', 'على', 'نون', 'حيَّ', 'إذاً', 'ج', 'د', 'والذين', 'ذاك', 'حاء', 'وراءَك', 'كلّما', 'ئ', 'أولالك', 'ابتدأ', 'بكن', 'إياي', 'تفعلين', 'واهاً', 'لكيلا', 'يورو', 'راح', 'أربعة', 'أسكن', 'عن', 'لدى', 'علم', 'جلل', 'جنيه', 'درى', 'أصبح', 'وا', 'كما', 'تسع', 'زود', 'ثمّة', 'قد', 'لا', 'أفريل', 'اللتيا', 'زاي', 'ست', 'هَذِه', 'لهم', 'هنالك', 'هاء', 'اخلولق', 'عند', 'عشرة', 'ذيت', 'بخٍ', 'معاذ', 'أنت', 'أوت', 'هاك', 'ستمئة', 'صباح', 'هذين', 'فوق', 'إليك', 'نا', 'فإن', 'لم', 'بغتة', 'جيم', 'ص', 'ثمنمئة', 'مادام', 'ولا', 'سابع', 'مكانَك', 'هَؤلاء', 'ا', 'سرا', 'تسعة', 'بَلْهَ', 'لوما', 'فيفري', 'ياء', 'هاتين', 'ذلك', 'أيار', 'أمامكَ', 'ماي', 'أولئك', 'وجد', 'أعطى', 'تحت', 'قطّ', 'هل', 'ثالث', 'طاء', 'فاء', 'ن', 'هَذِي', 'إليكم', 'أولاء', 'آض', 'حاشا', 'تاسع', 'يونيو', 'أربع', 'فيه', 'كانون', 'بين', 'تلقاء', 'غ', 'إي', 'إزاء', 'بضع', 'عليك', 'أن', 'بماذا', 'كيف', 'ارتدّ', 'ه', 'هيهات', 'كسا', 'لو', 'ثمة', 'تفعلان', 'ذَيْنِ', 'آه', 'ساء', 'أقبل', 'وَيْ', 'عشر', 'خلافا', 'مساء', 'إنه', 'ألا', 'أوه', 'أجمع', 'نفس', 'استحال', 'خلا', 'بهم', 'آهاً', 'سبحان', 'غين', 'ثان', 'لكما', 'واو', 'فلان', 'مع', 'لنا', 'اربعين', 'كن', 'غداة', 'حمدا', 'آب', 'عَدَسْ', 'آي', 'تلكما', 'دينار', 'رُبَّ', 'جويلية', 'ثمَّ', 'ذه', 'إليكما', 'ء', 'كرب', 'لسنا', 'لها', 'ذ', 'فمن', 'خ', 'علًّ', 'يفعلون', 'لولا', 'الآن', 'ذانِ', 'همزة', 'إياه', 'سحقا', 'ثمان', 'ثلاثين', 'طالما', 'سبت', 'حمٌ', 'كل', 'أيّ', 'أنتم', 'إياكن', 'سوف', 'آهٍ', 'ثاني', 'ظ', 'عاد', 'خبَّر', 'ضاد', 'اربعون', 'هيا', 'نعم', 'هنا', 'تسعين', 'يفعلان', 'خمسين', 'اثنان', 'جير', 'أربعمائة', 'ذي', 'إذن', 'ثلاثمائة', 'ذانك', 'رزق', 'اللتين', 'لكن', 'فرادى', 'سبع', 'هؤلاء', 'أطعم', 'التي', 'مهما', 'لعل', 'هاكَ', 'بمن', 'أم', 'نحو', 'ث', 'ط', 'هذان', 'إلَيْكَ', 'وهب', 'عدَّ', 'ليت', 'طَق', 'خامس', 'أهلا', 'شمال', 'جمعة', 'ذينك', 'هاهنا', 'ثم', 'اثني', 'ليسوا', 'ذو', 'أيا', 'هَيْهات', 'كى', 'بس', 'الذي', 'بل', 'دواليك', 'مائة', 'ممن', 'جعل', 'من', 'تانِ', 'شبه', 'إياهما', 'ذلكن', 'هما', 'حبذا', 'راء', 'نَخْ', 'آ', 'حاي', 'تعسا', 'لات', 'بنا', 'أيها', 'ها', 'أمّا', 'ش', 'اللذين', 'ثماني', 'صراحة', 'قام', 'هَذا', 'كأن', 'تلك', 'نحن', 'هي', 'هيت', 'ثامن', 'هلّا', 'قلما', 'هاته', 'أبدا', 'وهو', 'فبراير', 'إليكنّ', 'خاصة', 'حمو', 'لهما', 'إحدى', 'ثلاثون', 'مذ', 'ع', 'ستين', 'يوان', 'تانِك', 'الألى', 'أ', 'جانفي', 'صبر', 'فيما', 'تاء', 'ته', 'اللتان', 'مكانكما', 'صدقا', 'س', 'إليكَ', 'خاء', 'انبرى', 'نبَّا', 'ترك', 'ألفى', 'ّأيّان', 'شَتَّانَ', 'دون', 'له', 'عوض', 'إذما', 'عامة', 'إنَّ', 'ورد', 'هناك', 'يا', 'شتانَ', 'ليس', 'كي', 'تبدّل', 'هبّ', 'و', 'أقل', 'أيّان', 'انقلب', 'كلما', 'آها', 'لام', 'هاتي', 'تَيْنِ', 'غالبا', 'بها', 'حار', 'إليكن', 'سرعان', 'فإذا', 'طرا', 'آهِ', 'ماذا', 'مازال', 'أمام', 'اللاتي', 'مايو', 'هَذانِ', 'أربعمئة', 'ديسمبر', 'إيه', 'حين', 'ظلّ', 'ثلاثة', 'كلا', 'قرش', 'ما برح', 'اللواتي', 'ى', 'لي', 'أصلا', 'هذه', 'ظنَّ', 'ذال', 'عسى', 'مكانكم', 'شباط', 'منه', 'إياكما', 'إمّا', 'كذا', 'أمس', 'ذلكما', 'أنا', 'اثنين', 'وإن', 'طفق', 'كلاهما', 'جوان', 'شرع', 'ز', 'بكما', 'سبتمبر', 'ثلاثاء', 'ولكن', 'كاف', 'نَّ', 'أخذ', 'لن', 'عجبا', 'أنبأ', 'كأيّ', 'حقا', 'خمسون', 'غادر', 'ر', 'هيّا', 'هَاتِي', 'إلى', 'ثاء', 'كلتا', 'خمسمائة', 'هَاتَيْنِ', 'كيفما', 'ريال', 'إى', 'صهٍ', 'كأنّ', 'هو', 'ذان', 'وما', 'متى', 'خمسة', 'الألاء', 'أوشك', 'دونك', 'يناير', 'دولار', 'إما', 'منذ', 'ثمانمئة', 'آناء', 'بلى', 'صار', 'أنًّ', 'نوفمبر', 'حيث'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('arabic'))\n",
    "print(\"Stop words: \",stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub(r'@\\w+', '', text)  \n",
    "    text = re.sub(r'#\\w+', '', text)  \n",
    "    text = re.sub(r'http\\S+', '', text)  \n",
    "    text = re.sub(r'[^\\w\\s,]', '', text)\n",
    "    # Supprimer les caractères qui ne sont pas en arabe\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
    "\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = nltk.word_tokenize(text)    \n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words] \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    cleaned_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ذات يوم قال ستالين، وهو بالمناسبة أبشع أمين عا...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>يوم قال ستالين بالمناسبة أبشع أمين عام حزب منت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قال الرئيس التركي رجب طيب أردوغان إن بنيامين ن...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>قال الرئيس التركي رجب طيب أردوغان بنيامين نتني...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دخل حزب الأصالة والمعاصرة في الآونة الأخيرة، م...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>دخل حزب الأصالة والمعاصرة الآونة الأخيرة مرحلة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>استطاع الفلسطينيون أن يحققوا انتصارا كبيرا على...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>استطاع الفلسطينيون يحققوا انتصارا كبيرا إسرائي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>لا يزال جثمان لينين المحنط مسجى في ضريحه في ال...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>يزال جثمان لينين المحنط مسجى ضريحه الساحة الحم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>شرعية(بمعنى الحفاظ على استقرار الوطن المغربي) ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>شرعيةبمعنى الحفاظ استقرار الوطن المغربي الملك ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>أعلن مؤخرا الحبيب المالكي (الصورة) عضو المكتب ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>أعلن مؤخرا الحبيب المالكي الصورة عضو المكتب ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>كان الكثير من المغاربة يُقدرون أن الحسن الثان...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>الكثير المغاربة يقدرون الحسن الثاني قابل للموت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>أربعون سنة مرت على ثورة الشباب في اروبة في ماي...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>أربعون سنة مرت ثورة الشباب اروبة أربعون سنة مر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>مرت أمس الأربعاء الذكرى الخامسة والخمسون لوفاة...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>مرت الأربعاء الذكرى الخامسة والخمسون لوفاة الش...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  score  \\\n",
       "0    ذات يوم قال ستالين، وهو بالمناسبة أبشع أمين عا...   10.0   \n",
       "1    قال الرئيس التركي رجب طيب أردوغان إن بنيامين ن...    2.0   \n",
       "2    دخل حزب الأصالة والمعاصرة في الآونة الأخيرة، م...    4.0   \n",
       "3    استطاع الفلسطينيون أن يحققوا انتصارا كبيرا على...    5.0   \n",
       "4    لا يزال جثمان لينين المحنط مسجى في ضريحه في ال...   10.0   \n",
       "..                                                 ...    ...   \n",
       "220  شرعية(بمعنى الحفاظ على استقرار الوطن المغربي) ...    3.0   \n",
       "221  أعلن مؤخرا الحبيب المالكي (الصورة) عضو المكتب ...   10.0   \n",
       "222   كان الكثير من المغاربة يُقدرون أن الحسن الثان...    9.0   \n",
       "223  أربعون سنة مرت على ثورة الشباب في اروبة في ماي...   10.0   \n",
       "224  مرت أمس الأربعاء الذكرى الخامسة والخمسون لوفاة...   10.0   \n",
       "\n",
       "                                            clean_text  \n",
       "0    يوم قال ستالين بالمناسبة أبشع أمين عام حزب منت...  \n",
       "1    قال الرئيس التركي رجب طيب أردوغان بنيامين نتني...  \n",
       "2    دخل حزب الأصالة والمعاصرة الآونة الأخيرة مرحلة...  \n",
       "3    استطاع الفلسطينيون يحققوا انتصارا كبيرا إسرائي...  \n",
       "4    يزال جثمان لينين المحنط مسجى ضريحه الساحة الحم...  \n",
       "..                                                 ...  \n",
       "220  شرعيةبمعنى الحفاظ استقرار الوطن المغربي الملك ...  \n",
       "221  أعلن مؤخرا الحبيب المالكي الصورة عضو المكتب ال...  \n",
       "222  الكثير المغاربة يقدرون الحسن الثاني قابل للموت...  \n",
       "223  أربعون سنة مرت ثورة الشباب اروبة أربعون سنة مر...  \n",
       "224  مرت الأربعاء الذكرى الخامسة والخمسون لوفاة الش...  \n",
       "\n",
       "[220 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'clean_text'] = df['text'].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarabic.araby as araby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sre_parse import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define a function to tokenize text\n",
    "def tokenize_text(text):\n",
    "    tokens = araby.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization to each text in the DataFrame\n",
    "df.loc[:, 'tokenized_text'] = df['clean_text'].apply(tokenize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ذات يوم قال ستالين، وهو بالمناسبة أبشع أمين عا...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>يوم قال ستالين بالمناسبة أبشع أمين عام حزب منت...</td>\n",
       "      <td>[يوم, قال, ستالين, بالمناسبة, أبشع, أمين, عام,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قال الرئيس التركي رجب طيب أردوغان إن بنيامين ن...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>قال الرئيس التركي رجب طيب أردوغان بنيامين نتني...</td>\n",
       "      <td>[قال, الرئيس, التركي, رجب, طيب, أردوغان, بنيام...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دخل حزب الأصالة والمعاصرة في الآونة الأخيرة، م...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>دخل حزب الأصالة والمعاصرة الآونة الأخيرة مرحلة...</td>\n",
       "      <td>[دخل, حزب, الأصالة, والمعاصرة, الآونة, الأخيرة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>استطاع الفلسطينيون أن يحققوا انتصارا كبيرا على...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>استطاع الفلسطينيون يحققوا انتصارا كبيرا إسرائي...</td>\n",
       "      <td>[استطاع, الفلسطينيون, يحققوا, انتصارا, كبيرا, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>لا يزال جثمان لينين المحنط مسجى في ضريحه في ال...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>يزال جثمان لينين المحنط مسجى ضريحه الساحة الحم...</td>\n",
       "      <td>[يزال, جثمان, لينين, المحنط, مسجى, ضريحه, السا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>شرعية(بمعنى الحفاظ على استقرار الوطن المغربي) ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>شرعيةبمعنى الحفاظ استقرار الوطن المغربي الملك ...</td>\n",
       "      <td>[شرعيةبمعنى, الحفاظ, استقرار, الوطن, المغربي, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>أعلن مؤخرا الحبيب المالكي (الصورة) عضو المكتب ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>أعلن مؤخرا الحبيب المالكي الصورة عضو المكتب ال...</td>\n",
       "      <td>[أعلن, مؤخرا, الحبيب, المالكي, الصورة, عضو, ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>كان الكثير من المغاربة يُقدرون أن الحسن الثان...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>الكثير المغاربة يقدرون الحسن الثاني قابل للموت...</td>\n",
       "      <td>[الكثير, المغاربة, يقدرون, الحسن, الثاني, قابل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>أربعون سنة مرت على ثورة الشباب في اروبة في ماي...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>أربعون سنة مرت ثورة الشباب اروبة أربعون سنة مر...</td>\n",
       "      <td>[أربعون, سنة, مرت, ثورة, الشباب, اروبة, أربعون...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>مرت أمس الأربعاء الذكرى الخامسة والخمسون لوفاة...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>مرت الأربعاء الذكرى الخامسة والخمسون لوفاة الش...</td>\n",
       "      <td>[مرت, الأربعاء, الذكرى, الخامسة, والخمسون, لوف...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  score  \\\n",
       "0    ذات يوم قال ستالين، وهو بالمناسبة أبشع أمين عا...   10.0   \n",
       "1    قال الرئيس التركي رجب طيب أردوغان إن بنيامين ن...    2.0   \n",
       "2    دخل حزب الأصالة والمعاصرة في الآونة الأخيرة، م...    4.0   \n",
       "3    استطاع الفلسطينيون أن يحققوا انتصارا كبيرا على...    5.0   \n",
       "4    لا يزال جثمان لينين المحنط مسجى في ضريحه في ال...   10.0   \n",
       "..                                                 ...    ...   \n",
       "220  شرعية(بمعنى الحفاظ على استقرار الوطن المغربي) ...    3.0   \n",
       "221  أعلن مؤخرا الحبيب المالكي (الصورة) عضو المكتب ...   10.0   \n",
       "222   كان الكثير من المغاربة يُقدرون أن الحسن الثان...    9.0   \n",
       "223  أربعون سنة مرت على ثورة الشباب في اروبة في ماي...   10.0   \n",
       "224  مرت أمس الأربعاء الذكرى الخامسة والخمسون لوفاة...   10.0   \n",
       "\n",
       "                                            clean_text  \\\n",
       "0    يوم قال ستالين بالمناسبة أبشع أمين عام حزب منت...   \n",
       "1    قال الرئيس التركي رجب طيب أردوغان بنيامين نتني...   \n",
       "2    دخل حزب الأصالة والمعاصرة الآونة الأخيرة مرحلة...   \n",
       "3    استطاع الفلسطينيون يحققوا انتصارا كبيرا إسرائي...   \n",
       "4    يزال جثمان لينين المحنط مسجى ضريحه الساحة الحم...   \n",
       "..                                                 ...   \n",
       "220  شرعيةبمعنى الحفاظ استقرار الوطن المغربي الملك ...   \n",
       "221  أعلن مؤخرا الحبيب المالكي الصورة عضو المكتب ال...   \n",
       "222  الكثير المغاربة يقدرون الحسن الثاني قابل للموت...   \n",
       "223  أربعون سنة مرت ثورة الشباب اروبة أربعون سنة مر...   \n",
       "224  مرت الأربعاء الذكرى الخامسة والخمسون لوفاة الش...   \n",
       "\n",
       "                                        tokenized_text  \n",
       "0    [يوم, قال, ستالين, بالمناسبة, أبشع, أمين, عام,...  \n",
       "1    [قال, الرئيس, التركي, رجب, طيب, أردوغان, بنيام...  \n",
       "2    [دخل, حزب, الأصالة, والمعاصرة, الآونة, الأخيرة...  \n",
       "3    [استطاع, الفلسطينيون, يحققوا, انتصارا, كبيرا, ...  \n",
       "4    [يزال, جثمان, لينين, المحنط, مسجى, ضريحه, السا...  \n",
       "..                                                 ...  \n",
       "220  [شرعيةبمعنى, الحفاظ, استقرار, الوطن, المغربي, ...  \n",
       "221  [أعلن, مؤخرا, الحبيب, المالكي, الصورة, عضو, ال...  \n",
       "222  [الكثير, المغاربة, يقدرون, الحسن, الثاني, قابل...  \n",
       "223  [أربعون, سنة, مرت, ثورة, الشباب, اروبة, أربعون...  \n",
       "224  [مرت, الأربعاء, الذكرى, الخامسة, والخمسون, لوف...  \n",
       "\n",
       "[220 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, GRU, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df\n",
    "# Preprocessing\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['clean_text'])\n",
    "X = tokenizer.texts_to_sequences(data['clean_text'])\n",
    "X = pad_sequences(X)\n",
    "\n",
    "# Normalize target variable\n",
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36991508],\n",
       "       [-1.00784679],\n",
       "       [-0.41340633],\n",
       "       [-0.11618609],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 0.47825438],\n",
       "       [-0.11618609],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [-1.00784679],\n",
       "       [ 0.77547461],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [ 0.47825438],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [-0.41340633],\n",
       "       [ 1.36991508],\n",
       "       [ 0.18103414],\n",
       "       [ 0.77547461],\n",
       "       [-0.41340633],\n",
       "       [-1.00784679],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [-0.41340633],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [-0.11618609],\n",
       "       [-1.00784679],\n",
       "       [-1.00784679],\n",
       "       [-0.41340633],\n",
       "       [-0.41340633],\n",
       "       [ 0.18103414],\n",
       "       [ 0.18103414],\n",
       "       [-0.71062656],\n",
       "       [-1.00784679],\n",
       "       [ 0.18103414],\n",
       "       [-1.00784679],\n",
       "       [-0.41340633],\n",
       "       [-1.00784679],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 1.07269484],\n",
       "       [ 1.07269484],\n",
       "       [-1.00784679],\n",
       "       [ 1.36991508],\n",
       "       [ 0.47825438],\n",
       "       [-0.41340633],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 0.47825438],\n",
       "       [ 1.07269484],\n",
       "       [-0.11618609],\n",
       "       [-0.71062656],\n",
       "       [ 0.47825438],\n",
       "       [ 0.47825438],\n",
       "       [ 0.47825438],\n",
       "       [-0.41340633],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 1.07269484],\n",
       "       [-0.41340633],\n",
       "       [ 1.36991508],\n",
       "       [ 0.18103414],\n",
       "       [ 0.47825438],\n",
       "       [ 0.47825438],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [ 1.07269484],\n",
       "       [-0.11618609],\n",
       "       [ 0.18103414],\n",
       "       [ 1.36991508],\n",
       "       [ 0.18103414],\n",
       "       [ 1.36991508],\n",
       "       [ 0.18103414],\n",
       "       [ 1.07269484],\n",
       "       [ 0.18103414],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [ 1.36991508],\n",
       "       [-1.00784679],\n",
       "       [-0.71062656],\n",
       "       [ 0.47825438],\n",
       "       [-0.71062656],\n",
       "       [-0.41340633],\n",
       "       [ 0.18103414],\n",
       "       [-0.71062656],\n",
       "       [-0.71062656],\n",
       "       [-1.00784679],\n",
       "       [-0.11618609],\n",
       "       [-1.00784679],\n",
       "       [-0.71062656],\n",
       "       [-0.71062656],\n",
       "       [ 0.47825438],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [-1.30506703],\n",
       "       [-0.41340633],\n",
       "       [-0.41340633],\n",
       "       [-0.71062656],\n",
       "       [ 1.07269484],\n",
       "       [ 0.18103414],\n",
       "       [ 0.47825438],\n",
       "       [-0.11618609],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [ 1.07269484],\n",
       "       [-0.11618609],\n",
       "       [-1.00784679],\n",
       "       [-0.71062656],\n",
       "       [ 0.47825438],\n",
       "       [-0.71062656],\n",
       "       [ 0.47825438],\n",
       "       [-0.41340633],\n",
       "       [ 0.18103414],\n",
       "       [-0.11618609],\n",
       "       [ 1.07269484],\n",
       "       [ 0.18103414],\n",
       "       [ 1.36991508],\n",
       "       [ 0.18103414],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [-0.41340633],\n",
       "       [ 1.36991508],\n",
       "       [ 0.18103414],\n",
       "       [ 1.07269484],\n",
       "       [-0.71062656],\n",
       "       [-0.71062656],\n",
       "       [-0.71062656],\n",
       "       [-0.71062656],\n",
       "       [ 0.18103414],\n",
       "       [ 0.47825438],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [-0.11618609],\n",
       "       [ 0.18103414],\n",
       "       [-0.41340633],\n",
       "       [ 0.18103414],\n",
       "       [ 1.07269484],\n",
       "       [-1.00784679],\n",
       "       [-1.00784679],\n",
       "       [-0.71062656],\n",
       "       [-0.11618609],\n",
       "       [-0.41340633],\n",
       "       [-0.71062656],\n",
       "       [ 1.36991508],\n",
       "       [ 0.47825438],\n",
       "       [-0.71062656],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [-0.41340633],\n",
       "       [ 1.07269484],\n",
       "       [-0.71062656],\n",
       "       [-0.71062656],\n",
       "       [ 1.07269484],\n",
       "       [ 0.18103414],\n",
       "       [-0.71062656],\n",
       "       [ 1.36991508],\n",
       "       [-0.41340633],\n",
       "       [-1.00784679],\n",
       "       [ 1.36991508],\n",
       "       [-1.00784679],\n",
       "       [-0.71062656],\n",
       "       [ 0.47825438],\n",
       "       [-0.11618609],\n",
       "       [-1.00784679],\n",
       "       [-1.00784679],\n",
       "       [-0.71062656],\n",
       "       [-0.41340633],\n",
       "       [-0.71062656],\n",
       "       [-1.60228726],\n",
       "       [-1.60228726],\n",
       "       [-1.60228726],\n",
       "       [-1.60228726],\n",
       "       [-1.60228726],\n",
       "       [-1.60228726],\n",
       "       [-1.00784679],\n",
       "       [-1.60228726],\n",
       "       [-1.60228726],\n",
       "       [-1.30506703],\n",
       "       [-1.30506703],\n",
       "       [-1.60228726],\n",
       "       [-1.60228726],\n",
       "       [-1.30506703],\n",
       "       [-1.30506703],\n",
       "       [-1.30506703],\n",
       "       [-1.30506703],\n",
       "       [-1.30506703],\n",
       "       [-1.60228726],\n",
       "       [-1.30506703],\n",
       "       [-1.60228726],\n",
       "       [-1.30506703],\n",
       "       [-1.60228726],\n",
       "       [-1.60228726],\n",
       "       [-1.30506703],\n",
       "       [-1.60228726],\n",
       "       [-1.30506703],\n",
       "       [-0.11618609],\n",
       "       [ 0.47825438],\n",
       "       [-0.71062656],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508],\n",
       "       [-1.60228726],\n",
       "       [-0.71062656],\n",
       "       [-1.00784679],\n",
       "       [ 1.36991508],\n",
       "       [-0.71062656],\n",
       "       [ 1.36991508],\n",
       "       [ 1.07269484],\n",
       "       [ 1.36991508],\n",
       "       [ 1.36991508]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architectures\n",
    "def build_rnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_shape=input_shape),\n",
    "        LSTM(64),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_bidirectional_rnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_shape=input_shape),\n",
    "        Bidirectional(LSTM(64)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_shape=input_shape),\n",
    "        GRU(64),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_shape=input_shape),\n",
    "        LSTM(64),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train the models\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=64):\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9s/step - loss: 1.0286 - val_loss: 1.0768\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7s/step - loss: 0.9546 - val_loss: 1.0728\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8s/step - loss: 0.9215 - val_loss: 1.0655\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7s/step - loss: 0.8331 - val_loss: 1.0502\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7s/step - loss: 0.6870 - val_loss: 0.9973\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6s/step - loss: 0.3491 - val_loss: 0.7765\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6s/step - loss: 0.2575 - val_loss: 0.9756\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6s/step - loss: 0.0979 - val_loss: 1.0607\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6s/step - loss: 0.0963 - val_loss: 1.0800\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6s/step - loss: 0.0729 - val_loss: 1.0639\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 19s/step - loss: 0.9688 - val_loss: 1.0858\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 22s/step - loss: 0.9582 - val_loss: 1.0921\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 21s/step - loss: 0.9036 - val_loss: 1.0823\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 21s/step - loss: 0.8937 - val_loss: 1.0691\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 23s/step - loss: 0.8033 - val_loss: 1.0602\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 18s/step - loss: 0.6761 - val_loss: 1.0376\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 22s/step - loss: 0.4561 - val_loss: 0.8816\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 22s/step - loss: 0.2066 - val_loss: 0.9761\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 26s/step - loss: 0.0890 - val_loss: 1.1230\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 31s/step - loss: 0.1018 - val_loss: 1.1439\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 10s/step - loss: 0.9949 - val_loss: 1.0677\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7s/step - loss: 0.9509 - val_loss: 1.0692\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9s/step - loss: 0.9305 - val_loss: 1.0669\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7s/step - loss: 0.8884 - val_loss: 1.0633\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8s/step - loss: 0.8182 - val_loss: 1.0604\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 8s/step - loss: 0.6549 - val_loss: 1.0541\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8s/step - loss: 0.5892 - val_loss: 1.0450\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8s/step - loss: 0.3861 - val_loss: 1.0271\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7s/step - loss: 0.1936 - val_loss: 1.0042\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8s/step - loss: 0.1039 - val_loss: 1.0233\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11s/step - loss: 0.9969 - val_loss: 1.0782\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8s/step - loss: 0.9633 - val_loss: 1.0689\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9s/step - loss: 0.9046 - val_loss: 1.0593\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8s/step - loss: 0.8581 - val_loss: 1.0397\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7s/step - loss: 0.6707 - val_loss: 0.9966\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7s/step - loss: 0.3851 - val_loss: 0.7863\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6s/step - loss: 0.2126 - val_loss: 0.9891\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7s/step - loss: 0.1072 - val_loss: 1.0766\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6s/step - loss: 0.0955 - val_loss: 1.1044\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6s/step - loss: 0.0680 - val_loss: 1.0968\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 444ms/step\n",
      "RNN Model MSE: 0.7389347959938188\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8s/step\n",
      "Bidirectional RNN Model MSE: 0.7480776578849453\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027ECE838E00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027ECE838E00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 824ms/step\n",
      "GRU Model MSE: 0.759595352819302\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646ms/step\n",
      "LSTM Model MSE: 0.6951840131473881\n"
     ]
    }
   ],
   "source": [
    "# Build and train RNN model\n",
    "rnn_model = build_rnn_model(X_train.shape[1:])\n",
    "rnn_history = train_model(rnn_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Build and train Bidirectional RNN model\n",
    "bidirectional_rnn_model = build_bidirectional_rnn_model(X_train.shape[1:])\n",
    "bidirectional_rnn_history = train_model(bidirectional_rnn_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Build and train GRU model\n",
    "gru_model = build_gru_model(X_train.shape[1:])\n",
    "gru_history = train_model(gru_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Build and train LSTM model\n",
    "lstm_model = build_lstm_model(X_train.shape[1:])\n",
    "lstm_history = train_model(lstm_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Evaluate the models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "rnn_mse = evaluate_model(rnn_model, X_test, y_test)\n",
    "print(\"RNN Model MSE:\", rnn_mse)\n",
    "\n",
    "bidirectional_rnn_mse = evaluate_model(bidirectional_rnn_model, X_test, y_test)\n",
    "print(\"Bidirectional RNN Model MSE:\", bidirectional_rnn_mse)\n",
    "\n",
    "gru_mse = evaluate_model(gru_model, X_test, y_test)\n",
    "print(\"GRU Model MSE:\", gru_mse)\n",
    "\n",
    "lstm_mse = evaluate_model(lstm_model, X_test, y_test)\n",
    "print(\"LSTM Model MSE:\", lstm_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 30s/step - loss: 1.0043 - val_loss: 1.0816\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26s/step - loss: 1.0043 - val_loss: 1.0754\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 32s/step - loss: 0.9628 - val_loss: 1.0634\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 39s/step - loss: 0.8436 - val_loss: 1.0372\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 26s/step - loss: 0.6708 - val_loss: 0.9491\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26s/step - loss: 0.2797 - val_loss: 0.8244\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26s/step - loss: 0.1858 - val_loss: 0.9416\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26s/step - loss: 0.0888 - val_loss: 0.9483\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 31s/step - loss: 0.1049 - val_loss: 0.9311\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_12_1/bidirectional_4_1/backward_lstm_10_1/TensorArrayUnstack/TensorListFromTensor defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_11088\\2661469495.py\", line 59, in <module>\n\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_11088\\2661469495.py\", line 50, in train_model\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 314, in fit\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in one_step_on_data\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 51, in train_step\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 209, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 202, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 155, in _run_through_graph\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 592, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py\", line 221, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 560, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 406, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 555, in inner_loop\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 346, in inner_loop\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 245, in rnn\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 249, in <genexpr>\n\nOOM when allocating tensor with shape[64,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node sequential_12_1/bidirectional_4_1/backward_lstm_10_1/TensorArrayUnstack/TensorListFromTensor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_39890]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Build and train Bidirectional RNN model\u001b[39;00m\n\u001b[0;32m     58\u001b[0m bidirectional_rnn_model \u001b[38;5;241m=\u001b[39m build_bidirectional_rnn_model(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m---> 59\u001b[0m bidirectional_rnn_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbidirectional_rnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Build and train GRU model\u001b[39;00m\n\u001b[0;32m     62\u001b[0m gru_model \u001b[38;5;241m=\u001b[39m build_gru_model(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n",
      "Cell \u001b[1;32mIn[76], line 50\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, y_train, X_val, y_val, epochs, batch_size)\u001b[0m\n\u001b[0;32m     48\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node sequential_12_1/bidirectional_4_1/backward_lstm_10_1/TensorArrayUnstack/TensorListFromTensor defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_11088\\2661469495.py\", line 59, in <module>\n\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_11088\\2661469495.py\", line 50, in train_model\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 314, in fit\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in one_step_on_data\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 51, in train_step\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 209, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 202, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 155, in _run_through_graph\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 592, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py\", line 221, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 560, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 406, in call\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 555, in inner_loop\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 346, in inner_loop\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 245, in rnn\n\n  File \"c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 249, in <genexpr>\n\nOOM when allocating tensor with shape[64,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node sequential_12_1/bidirectional_4_1/backward_lstm_10_1/TensorArrayUnstack/TensorListFromTensor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_39890]"
     ]
    }
   ],
   "source": [
    "# Define model architectures\n",
    "def build_rnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_shape=input_shape),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.5),\n",
    "        LSTM(64),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_bidirectional_rnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_shape=input_shape),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        Dropout(0.5),\n",
    "        Bidirectional(LSTM(64)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_shape=input_shape),\n",
    "        GRU(64, return_sequences=True),\n",
    "        Dropout(0.5),\n",
    "        GRU(64),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_shape=input_shape),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.5),\n",
    "        LSTM(64),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train the models\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=64):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping], verbose=1)\n",
    "    return history\n",
    "\n",
    "# Build and train RNN model\n",
    "rnn_model = build_rnn_model(X_train.shape[1:])\n",
    "rnn_history = train_model(rnn_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Build and train Bidirectional RNN model\n",
    "bidirectional_rnn_model = build_bidirectional_rnn_model(X_train.shape[1:])\n",
    "bidirectional_rnn_history = train_model(bidirectional_rnn_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Build and train GRU model\n",
    "gru_model = build_gru_model(X_train.shape[1:])\n",
    "gru_history = train_model(gru_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Build and train LSTM model\n",
    "lstm_model = build_lstm_model(X_train.shape[1:])\n",
    "lstm_history = train_model(lstm_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Evaluate the models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "rnn_mse = evaluate_model(rnn_model, X_test, y_test)\n",
    "print(\"RNN Model MSE:\", rnn_mse)\n",
    "\n",
    "bidirectional_rnn_mse = evaluate_model(bidirectional_rnn_model, X_test, y_test)\n",
    "print(\"Bidirectional RNN Model MSE:\", bidirectional_rnn_mse)\n",
    "\n",
    "gru_mse = evaluate_model(gru_model, X_test, y_test)\n",
    "print(\"GRU Model MSE:\", gru_mse)\n",
    "\n",
    "lstm_mse = evaluate_model(lstm_model, X_test, y_test)\n",
    "print(\"LSTM Model MSE:\", lstm_mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
